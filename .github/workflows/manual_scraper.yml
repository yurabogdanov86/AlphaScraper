name: Automated Scraper Run

# Запускаем workflow вручную или автоматически каждый час
on:
  workflow_dispatch:
  schedule:
    - cron: "0 11-21 * * *"  # Запуск каждый час с 11:00 до 21:00

permissions:
  contents: write  # Разрешает workflow коммитить файлы в репозиторий

jobs:
  run-scraper:
    runs-on: ubuntu-latest  # Запуск на сервере Ubuntu
    steps:
      # 1️⃣ Клонируем репозиторий
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      # 2️⃣ Устанавливаем Chrome (если его нет)
      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      # 3️⃣ Устанавливаем Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # 4️⃣ Устанавливаем зависимости
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 5️⃣ Запускаем скрипт
      - name: Run scraper script
        run: python script.py
        env:
          TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TELEGRAM_CHANNEL_ID: ${{ secrets.TELEGRAM_CHANNEL_ID }}

      # 6️⃣ Коммитим изменения в previous_value.txt (если файл изменился)
      - name: Commit changes
        run: |
          if git diff --quiet; then
            echo "No changes detected. Skipping commit."
          else
            echo "Changes detected. Committing..."
            git config --global user.name 'github-actions[bot]'
            git config --global user.email 'github-actions[bot]@users.noreply.github.com'
            git add previous_value.txt
            git commit -m "Update previous_value.txt"
            git push
          fi
